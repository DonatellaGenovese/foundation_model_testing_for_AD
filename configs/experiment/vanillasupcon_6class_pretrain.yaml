# @package _global_

# to execute this experiment run:
# python src/train.py experiment=vanillasupcon_6class_pretrain paths=fm_testing_4090 data=collide2v_miniA6000

defaults:
  - override /data: collide2v_mini4090 #change wrt the data you want 
  - override /callbacks: supcon
  - override /trainer: gpu
  - override /logger: mlflow
  - override /model: vanilla_supcon  # ‚Üê Use base model config



# all parameters below will be merged with parameters from default configurations set above
# this allows you to overwrite only specified parameters

tags: ["collide2v", "vanillasupcon", "pretraining", "6class", "metric_learning"]

seed: 42

data:
  batch_size: 64  
  train_val_test_split_per_class: [200, 50, 50]  # Total 300 events per class, fits gamma (649 events)
  label: "v2_6class_highlevel"
  num_workers: 0
  to_classify:
    - "QCD_inclusive"
    - "DY_to_ll"
    - "Z_to_bb"
    - "W_to_lv"
    - "gamma"
    - "tt_all-lept"
  datasets_config:
    jets:
      cols:
        - FullReco_JetPuppiAK4_PT
        - FullReco_JetPuppiAK4_Eta
        - FullReco_JetPuppiAK4_Phi
        - FullReco_JetPuppiAK4_Mass
        - FullReco_JetPuppiAK4_BTag
        - FullReco_JetPuppiAK4_Charge
      topk: 12
      count: true

    electrons:
      cols:
        - FullReco_Electron_PT
        - FullReco_Electron_Eta
        - FullReco_Electron_Phi
        - FullReco_Electron_EhadOverEem
        - FullReco_Electron_IsolationVarRhoCorr
      topk: 8
      count: false

    muons:
      cols:
        - FullReco_MuonTight_PT
        - FullReco_MuonTight_Eta
        - FullReco_MuonTight_Phi
        - FullReco_MuonTight_IsolationVarRhoCorr
      topk: 8
      count: false

    photons:
      cols:
        - FullReco_PhotonTight_PT
        - FullReco_PhotonTight_Eta
        - FullReco_PhotonTight_Phi
      topk: 8
      count: false

    puppi_met:
      cols:
        - FullReco_PUPPIMET_MET
        - FullReco_PUPPIMET_Phi
      topk: null   # scalar values
      count: false

trainer:
  min_epochs: 2
  max_epochs: 10
  gradient_clip_algorithm: norm
  gradient_clip_val: 1.0
  #accumulate_grad_batches: 2  # Effective batch = 512 * 2 = 1024

model:
  # Architecture (override some params from base)
  n_heads: 8
  
  # Projection head
  projection_dim: 128
  hidden_projection_dim: 256
  
  # Loss
  temperature: 0.07  # Lowered from base 0.1 for harder negative mining
  use_classification_head: false
  
  # Optimizer (override)
  optimizer:
    lr: 0.0003  # Increased from base 0.0001
    weight_decay: 0.00001  # 1e-5
  
  # Scheduler (override)
  scheduler:
    T_max: ${trainer.max_epochs}  # Match trainer epochs
    eta_min: 0.000001  # 1e-6

preprocess:
  enabled: true

logger:
  mlflow:
    experiment_name: "supcon_pretraining"
    run_name: "vanillasupcon_6class_pretrain"

eval_after_training: true  # Enable automatic probe evaluation

eval:
  linear_probe:
    max_epochs: 50
    lr: 0.001
    weight_decay: 0.0
  
  knn_probe:
    k_values: [1, 3, 5, 10, 20]
    metric: 'cosine'
  
  output_dir: ${paths.output_dir}/probe_evaluation